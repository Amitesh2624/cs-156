{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc8cd957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "in_sample_data = []\n",
    "out_sample_data = []\n",
    "with open('in_dta.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        in_sample_data.append(line)\n",
    "\n",
    "with open('out_dta.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        out_sample_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "47b66cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(in_sample_data)):\n",
    "    act = in_sample_data[i].split(' ')\n",
    "    act2 = []\n",
    "    for val in act:\n",
    "        if val != '':\n",
    "            act2.append(float(val))\n",
    "    in_sample_data[i] = act2\n",
    "in_data = np.asarray(in_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "90bbfe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(out_sample_data)):\n",
    "    act = out_sample_data[i].split(' ')\n",
    "    act2 = []\n",
    "    for val in act:\n",
    "        if val != '':\n",
    "            act2.append(float(val))\n",
    "    out_sample_data[i] = act2\n",
    "out_data = np.asarray(out_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "52d17196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_linear_transform(X, k):\n",
    "    x_transformed = []\n",
    "    for x in X:\n",
    "        x1 = x[0]\n",
    "        x2 = x[1]\n",
    "        x_transformed.append([1, x1, x2, x1**2, x2**2, x1*x2, abs(x1 - x2), abs(x1 + x2)][:k+1])        \n",
    "    return np.asarray(x_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cddc9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    X_plus = np.linalg.inv(X.transpose().dot(X)).dot(X.transpose())\n",
    "    w = X_plus.dot(y)\n",
    "    return(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0112c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(X, w, y):\n",
    "    correct_pos = []\n",
    "    ct = 0\n",
    "    for x in X:\n",
    "        if np.sign(w.dot(x)) == y[ct]:\n",
    "            correct_pos.append(ct)\n",
    "        ct += 1\n",
    "    err = 1-len(correct_pos)/float(ct) \n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f0a1e813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3, v_err: 0.3 o_err: 0.42\n",
      "k = 4, v_err: 0.5 o_err: 0.42\n",
      "k = 5, v_err: 0.2 o_err: 0.19\n",
      "k = 6, v_err: 0.0 o_err: 0.08\n",
      "k = 7, v_err: 0.1 o_err: 0.07\n"
     ]
    }
   ],
   "source": [
    "X = in_data[:,:2][:25]\n",
    "y = in_data[:,2][:25]\n",
    "validation_X = in_data[:,:2][25:]\n",
    "validation_Y = in_data[:,2][25:]\n",
    "for k in range(3, 8):\n",
    "    Z = non_linear_transform(X, k)\n",
    "    w = linear_regression(Z,y)\n",
    "    Z_val = non_linear_transform(validation_X, k)\n",
    "    validation_error = get_error(Z_val,w,validation_Y)\n",
    "    test_X = out_data[:,:2]\n",
    "    test_Z = non_linear_transform(test_X, k)\n",
    "    test_y = out_data[:,2]\n",
    "    outer = get_error(test_Z, w,test_y)\n",
    "    print('k = '+ str(k) + ', v_err: ' + str(round(validation_error,2)) + ' o_err: ' + str(round(outer, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "90b613b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3, v_err: 0.28 o_err: 0.4\n",
      "k = 4, v_err: 0.36 o_err: 0.39\n",
      "k = 5, v_err: 0.2 o_err: 0.28\n",
      "k = 6, v_err: 0.08 o_err: 0.19\n",
      "k = 7, v_err: 0.12 o_err: 0.2\n"
     ]
    }
   ],
   "source": [
    "X = in_data[:,:2][25:]\n",
    "y = in_data[:,2][25:]\n",
    "validation_X = in_data[:,:2][:25]\n",
    "validation_Y = in_data[:,2][:25]\n",
    "for k in range(3, 8):\n",
    "    Z = non_linear_transform(X, k)\n",
    "    w = linear_regression(Z,y)\n",
    "    Z_val = non_linear_transform(validation_X, k)\n",
    "    validation_error = get_error(Z_val,w,validation_Y)\n",
    "    test_X = out_data[:,:2]\n",
    "    test_Z = non_linear_transform(test_X, k)\n",
    "    test_y = out_data[:,2]\n",
    "    outer = get_error(test_Z, w,test_y)\n",
    "    print('k = '+ str(k) + ', v_err: ' + str(round(validation_error,2)) + ' o_err: ' + str(round(outer, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "49dcdc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option (a), rho = 2.39\n",
      "Constant model error:  0.5\n",
      "Linear model error: 1.14\n",
      "------------------------------\n",
      "Option (b), rho = 0.86\n",
      "Constant model error:  0.5\n",
      "Linear model error: 64.66\n",
      "------------------------------\n",
      "Option (c), rho = 4.34\n",
      "Constant model error:  0.5\n",
      "Linear model error: 0.5\n",
      "------------------------------\n",
      "Option (d), rho = 2.56\n",
      "Constant model error:  0.5\n",
      "Linear model error: 0.99\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "rho_vals = [math.sqrt(math.sqrt(3) + 4), \n",
    "            math.sqrt(math.sqrt(3) - 1),\n",
    "            math.sqrt(9 + 4 * math.sqrt(6)),\n",
    "            math.sqrt(9 - math.sqrt(6))]\n",
    "\n",
    "for rho in rho_vals:\n",
    "    x = np.array([-1, rho, 1])\n",
    "    y = np.array([0, 1, 0])\n",
    "    e_const = 0\n",
    "    e_lin = 0\n",
    "    for i in range(3):\n",
    "        xval = x[i]\n",
    "        yval = y[i]\n",
    "        \n",
    "        xp = np.delete(x, i)\n",
    "        yp = np.delete(y, i)\n",
    "        \n",
    "        b = np.mean(yp)\n",
    "        e_const += (yval - b)**2\n",
    "        \n",
    "        xp = np.column_stack((np.ones(xp.shape), xp))\n",
    "        xval = np.array([1, xval])\n",
    "        Z = np.dot(np.linalg.inv(np.dot(xp.T, xp)), xp.T)\n",
    "        w = np.dot(Z, yp)\n",
    "        e_lin += (yval - np.dot(xval, w))**2\n",
    "    \n",
    "    print('Option ' + ['(a)', '(b)', '(c)', '(d)'][rho_vals.index(rho)] + ', rho = ' + str(round(rho,2)))\n",
    "    print('Constant model error: ', round(e_const/3, 2))\n",
    "    print('Linear model error: ' + str(round(e_lin/3, 2)), end ='\\n'+'-'*30 +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aa4a5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With N = 10, SVM is better than PLA 54.6% of the times\n",
      "With N = 100, SVM is better than PLA 74.1% of the times\n",
      "With N = 100, avg support vector count: 2.998\n"
     ]
    }
   ],
   "source": [
    "#!pip install numpy==1.26.3\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn import svm, model_selection\n",
    "\n",
    "num_experiments = 1000\n",
    "N = 10\n",
    "\n",
    "def label_data(X, m, b):\n",
    "    label = []\n",
    "    for x in X:\n",
    "        if x[2] >= (m * x[1] + b):\n",
    "            label.append(1)\n",
    "        else:\n",
    "            label.append(-1)\n",
    "    return label\n",
    "\n",
    "def generate_data(N):\n",
    "    #taking two random points to generate hypothesis\n",
    "    p1 = [np.random.uniform(-1,1), np.random.uniform(-1,1)]\n",
    "    p2 = [np.random.uniform(-1,1), np.random.uniform(-1,1)]\n",
    "\n",
    "    m = (p2[1] - p1[1])/(p2[0] - p1[0])\n",
    "    b = p1[1] - m * p1[0] #using slope to calculate intercept\n",
    "\n",
    "    X = np.insert(np.random.uniform(-1, 1, (N, 2)), 0, 1, axis=1)\n",
    "    #labelling data on the basis of said hypothesis\n",
    "    y = label_data(X, m, b)\n",
    "    while len(set(y)) == 1: \n",
    "    #making sure not all points fall on one side of the line\n",
    "        X = np.insert(np.random.uniform(-1, 1, (N, 2)), 0, 1, axis=1)\n",
    "        y = label_data(X, m, b)\n",
    "\n",
    "    X_test = np.insert(np.random.uniform(-1, 1, (5*N, 2)), 0, 1, axis=1)\n",
    "    y_test = get_y(X_test, m, b)\n",
    "\n",
    "    return (X, y, X_test, y_test)\n",
    "\n",
    "def PLA(N):\n",
    "    X, y, X_test, y_test = generate_data(N)\n",
    "    perceptron_model = Perceptron()\n",
    "    perceptron_model.fit(X, y)\n",
    "    return perceptron_model.score(X_test, y_test)\n",
    "\n",
    "def SVM(N):\n",
    "    X, y, X_test, y_test = generate_data(N)\n",
    "    svm_model = svm.SVC(kernel='linear', C=1000000000)\n",
    "    svm_model.fit(X, y)\n",
    "    return [len(svm_model.support_vectors_), svm_model.score(X_test, y_test)]\n",
    "\n",
    "count = 0\n",
    "for i in range(num_experiments):\n",
    "    if SVM(N)[1] > PLA(N):\n",
    "        count += 1\n",
    "print('With N = 10, SVM is better than PLA ' + str(100*count/num_experiments) + '% of the times')\n",
    "\n",
    "count = 0\n",
    "N = 100\n",
    "sv = 0\n",
    "for i in range(num_experiments):\n",
    "    svf = SVM(N)\n",
    "    sv += svf[0]\n",
    "    if svf[1] > PLA(N):\n",
    "        count += 1\n",
    "print('With N = 100, SVM is better than PLA ' + str(100*count/num_experiments) + '% of the times')\n",
    "print('With N = 100, avg support vector count: ' + str(sv/num_experiments))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
